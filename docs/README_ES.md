<h1 align="center">â— IntÃ©rprete Abierto</h1>

<p align="center">
    <a href="https://discord.gg/Hvz9Axh84z">
        <img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=flat&logoColor=white"/></a>
    <a href="../README.md"><img src="https://img.shields.io/badge/english-document-white.svg" alt="EN doc"></a>
    <a href="README_JA.md"><img src="https://img.shields.io/badge/ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ-æ—¥æœ¬èª-white.svg" alt="JA doc"/></a>
    <a href="README_ZH.md"> <img src="https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-white.svg" alt="ZH doc"/></a>
    <a href="README_UK.md"><img src="https://img.shields.io/badge/Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°-white.svg" alt="UK doc"/></a>
    <a href="README_IN.md"> <img src="https://img.shields.io/badge/Hindi-white.svg" alt="IN doc"/></a>
    <a href="../LICENSE"><img src="https://img.shields.io/static/v1?label=license&message=AGPL&color=white&style=flat" alt="License"/></a>
    <br>
    <br>
    <br><a href="https://0ggfznkwh4j.typeform.com/to/G21i9lJ2">Obtenga acceso temprano a la aplicaciÃ³n de escritorio</a>â€ â€ |â€ â€ <a href="https://docs.openinterpreter.com/">DocumentaciÃ³n</a><br>
</p>

<br>

![poster](https://github.com/OpenInterpreter/open-interpreter/assets/63927363/08f0d493-956b-4d49-982e-67d4b20c4b56)

<br>
<p align="center">
<strong>La Nueva ActualizaciÃ³n del Computador</strong> presenta <strong><code>--os</code></strong> y una nueva <strong>API de Computadora</strong>. <a href="https://changes.openinterpreter.com/log/the-new-computer-update">Lea mÃ¡s â†’</a>
</p>
<br>

```shell
pip install open-interpreter
```

> Â¿No funciona? Lea nuestra [guÃ­a de configuraciÃ³n](https://docs.openinterpreter.com/getting-started/setup).

```shell
interpreter
```

<br>

**IntÃ©rprete Abierto** permite a los LLMs ejecutar cÃ³digo (Python, JavaScript, Shell, etc.) localmente. Puede chatear con IntÃ©rprete Abierto a travÃ©s de una interfaz de chat como ChatGPT en su terminal despuÃ©s de instalar.

Esto proporciona una interfaz de lenguaje natural para las capacidades generales de su computadora:

- Crear y editar fotos, videos, PDF, etc.
- Controlar un navegador de Chrome para realizar investigaciones
- Graficar, limpiar y analizar conjuntos de datos grandes
- ... etc.

**âš ï¸ Nota: Se le pedirÃ¡ que apruebe el cÃ³digo antes de ejecutarlo.**

<br>

## Demo

https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60

#### TambiÃ©n hay disponible una demo interactiva en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing)

#### AdemÃ¡s, hay un ejemplo de interfaz de voz inspirada en _Her_:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1NojYGHDgxH6Y1G1oxThEBBb2AtyODBIK)

## Inicio RÃ¡pido

```shell
pip install open-interpreter
```

### Terminal

DespuÃ©s de la instalaciÃ³n, simplemente ejecute `interpreter`:

```shell
interpreter
```

### Python

```python
from interpreter import interpreter

interpreter.chat("Plot AAPL and META's normalized stock prices") # Ejecuta un comando sencillo
interpreter.chat() # Inicia una sesiÃ³n de chat interactiva
```

### GitHub Codespaces

Presione la tecla `,` en la pÃ¡gina de GitHub de este repositorio para crear un espacio de cÃ³digos. DespuÃ©s de un momento, recibirÃ¡ un entorno de mÃ¡quina virtual en la nube con Interprete Abierto pre-instalado. Puede entonces empezar a interactuar con Ã©l directamente y confirmar su ejecuciÃ³n de comandos del sistema sin preocuparse por daÃ±ar el sistema.

## ComparaciÃ³n con el IntÃ©rprete de CÃ³digo de ChatGPT

El lanzamiento de [IntÃ©rprete de CÃ³digo](https://openai.com/blog/chatgpt-plugins#code-interpreter) de OpenAI con GPT-4 presenta una oportunidad fantÃ¡stica para realizar tareas del mundo real con ChatGPT.

Sin embargo, el servicio de OpenAI estÃ¡ alojado, su codigo es cerrado y estÃ¡ fuertemente restringido:

- No hay acceso a Internet.
- [Conjunto limitado de paquetes preinstalados](https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/).
- LÃ­mite de 100 MB de carga, lÃ­mite de tiempo de 120.0 segundos.
- El estado se elimina (junto con cualquier archivo generado o enlace) cuando el entorno se cierra.

---

IntÃ©rprete Abierto supera estas limitaciones al ejecutarse en su entorno local. Tiene acceso completo a Internet, no estÃ¡ restringido por tiempo o tamaÃ±o de archivo y puede utilizar cualquier paquete o libreria.

Esto combina el poder del IntÃ©rprete de CÃ³digo de GPT-4 con la flexibilidad de su entorno de desarrollo local.

## Comandos

**ActualizaciÃ³n:** La ActualizaciÃ³n del Generador (0.1.5) introdujo streaming:

```python
message = "Â¿QuÃ© sistema operativo estamos utilizando?"

for chunk in interpreter.chat(message, display=False, stream=True):
    print(chunk)
```

### Chat Interactivo

Para iniciar una sesiÃ³n de chat interactiva en su terminal, puede ejecutar `interpreter` desde la lÃ­nea de comandos:

```shell
interpreter
```

O `interpreter.chat()` desde un archivo `.py`:

```python
interpreter.chat()
```

**Puede tambiÃ©n transmitir cada trozo:**

```python
message = "Â¿QuÃ© sistema operativo estamos utilizando?"

for chunk in interpreter.chat(message, display=False, stream=True):
    print(chunk)
```

### Chat ProgramÃ¡tico

Para un control mÃ¡s preciso, puede pasar mensajes directamente a `.chat(message)`:

```python
interpreter.chat("AÃ±ade subtÃ­tulos a todos los videos en /videos.")

# ... Transmite salida a su terminal, completa tarea ...

interpreter.chat("Estos se ven bien, pero Â¿pueden hacer los subtÃ­tulos mÃ¡s grandes?")

# ...
```

### Iniciar un nuevo chat

En Python, IntÃ©rprete Abierto recuerda el historial de conversaciÃ³n. Si desea empezar de nuevo, puede resetearlo:

```python
interpreter.messages = []
```

### Guardar y Restaurar Chats

`interpreter.chat()` devuelve una lista de mensajes, que puede utilizar para reanudar una conversaciÃ³n con `interpreter.messages = messages`:

```python
messages = interpreter.chat("Mi nombre es Killian.") # Guarda mensajes en 'messages'
interpreter.messages = [] # Resetear IntÃ©rprete ("Killian" serÃ¡ olvidado)

interpreter.messages = messages # Reanuda chat desde 'messages' ("Killian" serÃ¡ recordado)
```

### Personalizar el Mensaje del Sistema

Puede inspeccionar y configurar el mensaje del sistema de IntÃ©rprete Abierto para extender su funcionalidad, modificar permisos o darle mÃ¡s contexto.

```python
interpreter.system_message += """
Ejecute comandos de shell con -y para que el usuario no tenga que confirmarlos.
"""
print(interpreter.system_message)
```

### Cambiar el Modelo de Lenguaje

IntÃ©rprete Abierto utiliza [LiteLLM](https://docs.litellm.ai/docs/providers/) para conectarse a modelos de lenguaje hospedados.

Puede cambiar el modelo estableciendo el parÃ¡metro de modelo:

```shell
interpreter --model gpt-3.5-turbo
interpreter --model claude-2
interpreter --model command-nightly
```

En Python, establezca el modelo en el objeto:

```python
interpreter.llm.model = "gpt-3.5-turbo"
```

[Encuentre la cadena adecuada para su modelo de lenguaje aquÃ­.](https://docs.litellm.ai/docs/providers/)

### Ejecutar IntÃ©rprete Abierto localmente

#### Terminal

IntÃ©rprete Abierto puede utilizar un servidor de OpenAI compatible para ejecutar modelos localmente. (LM Studio, jan.ai, ollama, etc.)

Simplemente ejecute `interpreter` con la URL de base de API de su servidor de inferencia (por defecto, `http://localhost:1234/v1` para LM Studio):

```shell
interpreter --api_base "http://localhost:1234/v1" --api_key "fake_key"
```

O puede utilizar Llamafile sin instalar software adicional simplemente ejecutando:

```shell
interpreter --local
```

Para una guÃ­a mas detallada, consulte [este video de Mike Bird](https://www.youtube.com/watch?v=CEs51hGWuGU?si=cN7f6QhfT4edfG5H)

**CÃ³mo ejecutar LM Studio en segundo plano.**

1. Descargue [https://lmstudio.ai/](https://lmstudio.ai/) luego ejecutelo.
2. Seleccione un modelo, luego haga clic **â†“ Descargar**.
3. Haga clic en el botÃ³n **â†”ï¸** en la izquierda (debajo de ğŸ’¬).
4. Seleccione su modelo en la parte superior, luego haga clic **Iniciar Servidor**.

Una vez que el servidor estÃ© funcionando, puede empezar su conversaciÃ³n con IntÃ©rprete Abierto.

> **Nota:** El modo local establece su `context_window` en 3000 y su `max_tokens` en 1000. Si su modelo tiene requisitos diferentes, ajuste estos parÃ¡metros manualmente (ver a continuaciÃ³n).

#### Python

Nuestro paquete de Python le da mÃ¡s control sobre cada ajuste. Para replicar y conectarse a LM Studio, utilice estos ajustes:

```python
from interpreter import interpreter

interpreter.offline = True # Desactiva las caracterÃ­sticas en lÃ­nea como Procedimientos Abiertos
interpreter.llm.model = "openai/x" # Indica a OI que envÃ­e mensajes en el formato de OpenAI
interpreter.llm.api_key = "fake_key" # LiteLLM, que utilizamos para hablar con LM Studio, requiere esto
interpreter.llm.api_base = "http://localhost:1234/v1" # Apunta esto a cualquier servidor compatible con OpenAI

interpreter.chat()
```

#### Ventana de Contexto, Tokens MÃ¡ximos

Puede modificar los `max_tokens` y `context_window` (en tokens) de los modelos locales.

Para el modo local, ventanas de contexto mÃ¡s cortas utilizarÃ¡n menos RAM, asÃ­ que recomendamos intentar una ventana mucho mÃ¡s corta (~1000) si falla o si es lenta. AsegÃºrese de que `max_tokens` sea menor que `context_window`.

```shell
interpreter --local --max_tokens 1000 --context_window 3000
```

### Modo Detallado

Para ayudarle a inspeccionar IntÃ©rprete Abierto, tenemos un modo `--verbose` para depuraciÃ³n.

Puede activar el modo detallado utilizando el parÃ¡metro (`interpreter --verbose`), o en plena sesiÃ³n:

```shell
$ interpreter
...
> %verbose true <- Activa el modo detallado

> %verbose false <- Desactiva el modo verbose
```

### Comandos de Modo Interactivo

En el modo interactivo, puede utilizar los siguientes comandos para mejorar su experiencia. AquÃ­ hay una lista de comandos disponibles:

**Comandos Disponibles:**

- `%verbose [true/false]`: Activa o desactiva el modo detallado. Sin parÃ¡metros o con `true` entra en modo detallado.
  Con `false` sale del modo verbose.
- `%reset`: Reinicia la sesiÃ³n actual de conversaciÃ³n.
- `%undo`: Elimina el mensaje de usuario previo y la respuesta del AI del historial de mensajes.
- `%tokens [prompt]`: (_Experimental_) Calcula los tokens que se enviarÃ¡n con el prÃ³ximo prompt como contexto y estima su costo. Opcionalmente, calcule los tokens y el costo estimado de un `prompt` si se proporciona. Depende de [LiteLLM's `cost_per_token()` method](https://docs.litellm.ai/docs/completion/token_usage#2-cost_per_token) para costos estimados.
- `%help`: Muestra el mensaje de ayuda.

### ConfiguraciÃ³n / Perfiles

IntÃ©rprete Abierto permite establecer comportamientos predeterminados utilizando archivos `yaml`.

Esto proporciona una forma flexible de configurar el intÃ©rprete sin cambiar los argumentos de lÃ­nea de comandos cada vez.

Ejecutar el siguiente comando para abrir el directorio de perfiles:

```
interpreter --profiles
```

Puede agregar archivos `yaml` allÃ­. El perfil predeterminado se llama `default.yaml`.

#### Perfiles MÃºltiples

IntÃ©rprete Abierto admite mÃºltiples archivos `yaml`, lo que permite cambiar fÃ¡cilmente entre configuraciones:

```
interpreter --profile my_profile.yaml
```

## Servidor de FastAPI de ejemplo

El generador actualiza permite controlar IntÃ©rprete Abierto a travÃ©s de puntos de conexiÃ³n HTTP REST:

```python
# server.py

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from interpreter import interpreter

app = FastAPI()

@app.get("/chat")
def chat_endpoint(message: str):
    def event_stream():
        for result in interpreter.chat(message, stream=True):
            yield f"data: {result}\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")

@app.get("/history")
def history_endpoint():
    return interpreter.messages
```

```shell
pip install fastapi uvicorn
uvicorn server:app --reload
```

Puede iniciar un servidor idÃ©ntico al anterior simplemente ejecutando `interpreter.server()`.

## Android

La guÃ­a paso a paso para instalar IntÃ©rprete Abierto en su dispositivo Android se encuentra en el [repo de open-interpreter-termux](https://github.com/MikeBirdTech/open-interpreter-termux).

## Aviso de Seguridad

Ya que el cÃ³digo generado se ejecuta en su entorno local, puede interactuar con sus archivos y configuraciones del sistema, lo que puede llevar a resultados inesperados como pÃ©rdida de datos o riesgos de seguridad.

**âš ï¸ IntÃ©rprete Abierto le pedirÃ¡ que apruebe el cÃ³digo antes de ejecutarlo.**

Puede ejecutar `interpreter -y` o establecer `interpreter.auto_run = True` para evitar esta confirmaciÃ³n, en cuyo caso:

- Sea cuidadoso al solicitar comandos que modifican archivos o configuraciones del sistema.
- Vigile IntÃ©rprete Abierto como si fuera un coche autÃ³nomo y estÃ© preparado para terminar el proceso cerrando su terminal.
- Considere ejecutar IntÃ©rprete Abierto en un entorno restringido como Google Colab o Replit. Estos entornos son mÃ¡s aislados, reduciendo los riesgos de ejecutar cÃ³digo arbitrario.

Hay soporte **experimental** para un [modo seguro](docs/SAFE_MODE.md) para ayudar a mitigar algunos riesgos.

## Â¿CÃ³mo Funciona?

IntÃ©rprete Abierto equipa un [modelo de lenguaje de llamada a funciones](https://platform.openai.com/docs/guides/gpt/function-calling) con una funciÃ³n `exec()`, que acepta un `lenguaje` (como "Python" o "JavaScript") y `cÃ³digo` para ejecutar.

Luego, transmite los mensajes del modelo, el cÃ³digo y las salidas del sistema a la terminal como Markdown.

# Acceso a la DocumentaciÃ³n Offline

La documentaciÃ³n completa estÃ¡ disponible en lÃ­nea sin necesidad de conexiÃ³n a Internet.

[Node](https://nodejs.org/en) es un requisito previo:

- VersiÃ³n 18.17.0 o cualquier versiÃ³n posterior 18.x.x.
- VersiÃ³n 20.3.0 o cualquier versiÃ³n posterior 20.x.x.
- Cualquier versiÃ³n a partir de 21.0.0 sin lÃ­mite superior especificado.

Instale [Mintlify](https://mintlify.com/):

```bash
npm i -g mintlify@latest
```

Cambia a la carpeta de documentos y ejecuta el comando apropiado:

```bash
# Suponiendo que estÃ¡s en la carpeta raÃ­z del proyecto
cd ./docs

# Ejecute el servidor de documentaciÃ³n
mintlify dev
```

Una nueva ventana del navegador deberÃ­a abrirse. La documentaciÃ³n estarÃ¡ disponible en [http://localhost:3000](http://localhost:3000) mientras el servidor de documentaciÃ³n estÃ© funcionando.

# Contribuyendo

Â¡Gracias por su interÃ©s en contribuir! Damos la bienvenida a la implicaciÃ³n de la comunidad.

Por favor, consulte nuestras [directrices de contribuciÃ³n](docs/CONTRIBUTING.md) para obtener mÃ¡s detalles sobre cÃ³mo involucrarse.

# Roadmap

Visite [nuestro roadmap](https://github.com/OpenInterpreter/open-interpreter/blob/main/docs/ROADMAP.md) para ver el futuro de IntÃ©rprete Abierto.

**Nota:** Este software no estÃ¡ afiliado con OpenAI.

![thumbnail-ncu](https://github.com/OpenInterpreter/open-interpreter/assets/63927363/1b19a5db-b486-41fd-a7a1-fe2028031686)

> Tener acceso a un programador junior trabajando a la velocidad de su dedos... puede hacer que los nuevos flujos de trabajo sean sencillos y eficientes, ademÃ¡s de abrir los beneficios de la programaciÃ³n a nuevas audiencias.
>
> â€” _Lanzamiento del intÃ©rprete de cÃ³digo de OpenAI_

<br>
