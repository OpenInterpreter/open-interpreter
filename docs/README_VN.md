<h1 align="center">â— Open Interpreter</h1>

<p align="center">
    <a href="https://discord.gg/6p3fD6rBVm">
        <img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=flat&logoColor=white"/></a>
    <a href="docs/README_JA.md"><img src="https://img.shields.io/badge/ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ-æ—¥æœ¬èª-white.svg" alt="JA doc"/></a>
    <a href="docs/README_ZH.md"><img src="https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-white.svg" alt="ZH doc"/></a>
    <a href="docs/README_IN.md"><img src="https://img.shields.io/badge/Hindi-white.svg" alt="IN doc"/></a>
    <img src="https://img.shields.io/static/v1?label=license&message=MIT&color=white&style=flat" alt="License"/>
    <br>
    <br>
    <b>cháº¡y mÃ´ hÃ¬nh ngÃ´n ngá»¯ trÃ­ tuá»‡ nhÃ¢n táº¡o trÃªn mÃ¡y tÃ­nh cá»§a báº¡n.</b><br>
    MÃ£ nguá»“n má»Ÿ vÃ  á»©ng dá»¥ng phÃ¡t triá»ƒn dá»±a trÃªn code cá»§a OpenAI.<br>
    <br><a href="https://openinterpreter.com">Quyá»n truy cáº­p sá»›m dÃ nh cho mÃ¡y tÃ­nh cÃ¡ nhÃ¢n</a>â€ â€ |â€ â€ <b><a href="https://docs.openinterpreter.com/">TÃ i liá»‡u Ä‘á»c tham kháº£o</a></b><br>
</p>

<br>

![poster](https://github.com/KillianLucas/open-interpreter/assets/63927363/08f0d493-956b-4d49-982e-67d4b20c4b56)

<br>

```shell
pip install open-interpreter
```

```shell
interpreter
```

<br>

**Open Interpreter** Cháº¡y LLMs trÃªn mÃ¡y tÃ­nh cá»¥c bá»™ (CÃ³ thá»ƒ sá»­ dá»¥ng ngÃ´n ngá»¯ Python, Javascript, Shell, vÃ  nhiá»u hÆ¡n tháº¿). Báº¡n cÃ³ thá»ƒ nÃ³i chuyá»‡n vá»›i Open Interpreter thÃ´ng qua giao diá»‡n giá»‘ng vá»›i ChatGPT ngay trÃªn terminal cá»§a báº¡n báº±ng cÃ¡ch cháº¡y lá»‡nh `$ interpreter` sau khi táº£i thÃ nh cÃ´ng.

CÃ¡c tÃ­nh nÄƒng chung giao diá»‡n ngÃ´n ngá»¯ mang lláº¡i

- Táº¡o vÃ  chá»‰nh sá»­a áº£nh, videos, PDF, vÃ¢n vÃ¢n...
- Äiá»u khiá»ƒn trÃ¬nh duyá»‡t Chrome Ä‘á»ƒ tiáº¿n hÃ nh nghiÃªn cá»©u
- Váº½, lÃ m sáº¡ch vÃ  phÃ¢n tÃ­ch cÃ¡c táº­p dá»¯ liá»‡u lá»›n (large datasets)
- ...vÃ¢n vÃ¢n.

**âš ï¸ LÆ°u Ã½: Báº¡n sáº½ Ä‘Æ°á»£c yÃªu cáº§u phÃª duyá»‡t mÃ£ trÆ°á»›c khi cháº¡y.**

<br>

## Thá»­ nghiá»‡m

https://github.com/KillianLucas/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60

#### Báº£n thá»­ nghiá»‡m cÃ³ sáºµn trÃªn Google Colab:

[![Má»Ÿ trong Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing)

#### Äi kÃ¨m vá»›i á»©ng dá»¥ng máº«u qua tÆ°Æ¡ng tÃ¡c giá»ng nÃ³i (Láº¥y cáº£m há»©ng tá»« _CÃ´ áº¥y_ (Giá»ng ná»¯)):

[![Má»Ÿ trong Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1NojYGHDgxH6Y1G1oxThEBBb2AtyODBIK)

## HÆ°á»›ng dáº«n khá»Ÿi dá»™ng ngáº¯n

```shell
pip install open-interpreter
```

### Terminal

Sau khi cÃ i Ä‘áº·t, cháº¡y dÃ²ng lá»‡nh `interpreter`:

```shell
interpreter
```

### Python

```python
import interpreter

interpreter.chat("Váº½ giÃ¡ cá»• phiáº¿u Ä‘Ã£ bÃ¬nh hoÃ¡ cá»§a AAPL vÃ  META ") # Cháº¡y trÃªn 1 dÃ²ng lá»‡nh
interpreter.chat() # Khá»Ÿi Ä‘á»™ng chat cÃ³ kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c  
```

## So sÃ¡nh Code Interpreter cá»§a ChatGPT

Báº£n phÃ¡t hÃ nh cá»§a OpenAI [Code Interpreter](https://openai.com/blog/chatgpt-plugins#code-interpreter) sá»­ dá»¥ng GPT-4 tÄƒng kháº£ nÄƒng hoÃ n thiá»‡n váº¥n Ä‘á» thá»±c tiá»…n vá»›i ChatGPT.

Tuy nhiÃªn, dá»‹ch vá»¥ cá»§a OpenAI Ä‘Æ°á»£c lÆ°u trá»¯, mÃ£ nguá»“n Ä‘Ã³ng, vÃ  ráº¥t háº¡n cháº¿:

- KhÃ´ng cÃ³ truy cáº­p Internet.
- [Sá»‘ lÆ°á»£ng gÃ³i cÃ i Ä‘áº·t há»— trá»¡ cÃ³ sáºµn giá»›i háº¡n](https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/).
- tá»‘c Ä‘á»™ táº£i tá»‘i Ä‘a 100 MB , thá»i gian cháº¡y giá»›i háº¡n 120.0 giÃ¢y .
- Tráº¡ng thÃ¡i tin nháº¯n bá»‹ xoÃ¡ kÃ¨m vá»›i cÃ¡c tá»‡p vÃ  liÃªn káº¿t Ä‘Æ°á»£c táº¡o trÆ°á»›c Ä‘Ã³ khi Ä‘Ã³ng mÃ´i trÆ°á»ng láº¡i.

---
Open Interpreter kháº¯c phá»¥c nhá»¯ng háº¡n cháº¿ nÃ y báº±ng cÃ¡ch cháº¡y cá»¥c bá»™ trobá»™ mÃ´i trÆ°á»ng mÃ¡y tÃ­nh cá»§a báº¡n. NÃ³ cÃ³ toÃ n quyá»n truy cáº­p vÃ o Internet, khÃ´ng bá»‹ háº¡n cháº¿ vá» thá»i gian hoáº·c kÃ­ch thÆ°á»›c tá»‡p vÃ  cÃ³ thá»ƒ sá»­ dá»¥ng báº¥t ká»³ gÃ³i hoáº·c thÆ° viá»‡n nÃ o.

ÄÃ¢y lÃ  sá»± káº¿t há»£p sá»©c máº¡nh cá»§a mÃ£ nguá»“n cá»§a GPT-4 vá»›i tÃ­nh linh hoáº¡t cá»§a mÃ´i trÆ°á»ng phÃ¡t triá»ƒn cá»¥c bá»™ cá»§a báº¡n.


## DÃ²ng lá»‡nh

**Update:** Cáº­p nháº­t trÃ¬nh táº¡o lá»‡nh (0.1.5) giá»›i thiá»‡u tÃ­nh nÄƒng trá»±c tuyáº¿n:

```python
message = "ChÃºng ta Ä‘ang á»Ÿ trÃªn há»‡ Ä‘iá»u hÃ nh nÃ o?"

for chunk in interpreter.chat(message, display=False, stream=True):
  print(chunk)
```

### TrÃ² chuyá»‡n tÆ°Æ¡ng tÃ¡c

Äá»ƒ táº¡o má»™t cuá»™c trÃ² chuyá»‡n tÆ°Æ¡ng tÃ¡c tá»« terminal cá»§a báº¡n, cháº¡y `interpreter` báº±ng dÃ²ng lá»‡nh:

```shell
interpreter
```

hoáº·c `interpreter.chat()` tá»« file cÃ³ Ä‘uÃ´i .py :

```python
interpreter.chat()
```

**Báº¡n cÅ©ng cÃ³ thá»ƒ phÃ¡t trá»±c tuyáº¿n tá»«ng Ä‘oáº¡n:**

```python
message = "ChÃºng ta Ä‘ang cháº¡y trÃªn há»‡ Ä‘iá»u hÃ nh nÃ o?"

for chunk in interpreter.chat(message, display=False, stream=True):
  print(chunk)
```

### TrÃ² chuyá»‡n láº­p trÃ¬nh Ä‘Æ°á»£c

Äá»ƒ kiá»ƒm soÃ¡t tá»‘t hÆ¡n, báº¡n chuyá»ƒn tin nháº¯n qua `.chat(message)`:

```python
interpreter.chat("Truyá»n phá»¥ Ä‘á» tá»›i táº¥t cáº£ videos vÃ o /videos.")

# ... Truyá»n Ä‘áº§u ra Ä‘áº¿n thiáº¿t bá»‹ Ä‘áº§u cuá»‘i cá»§a báº¡n (terminal) hoÃ n thÃ nh tÃ¡c vá»¥ ...

interpreter.chat("NhÃ¬n Ä‘áº¹p Ä‘áº¥y nhÆ°ng báº¡n cÃ³ thá»ƒ lÃ m cho phá»¥ Ä‘á» lá»›n hÆ¡n Ä‘Æ°á»£c khÃ´ng?")

# ...
```

### Táº¡o má»™t cuá»™c trÃ² chuyá»‡n má»›i:

Trong Python, Open Interpreter ghi nhá»› lá»‹ch sá»­ há»™i thoáº¡i, náº¿u muá»‘n báº¯t Ä‘áº§u láº¡i tá»« Ä‘áº§u, báº¡n cÃ³ thá»ƒ cÃ i thá»©:

```python
interpreter.reset()
```

### LÆ°u vÃ  khÃ´i phá»¥c cuá»™c trÃ² chuyá»‡n

`interpreter.chat()` tráº£ vá» danh sÃ¡ch tin nháº¯n, cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tiáº¿p tá»¥c cuá»™c trÃ² chuyá»‡n vá»›i `interpreter.messages = messages`:

```python
messages = interpreter.chat("TÃªn cá»§a tÃ´i lÃ  Killian.") # LÆ°u tin nháº¯n tá»›i 'messages'
interpreter.reset() # Khá»Ÿi Ä‘á»™ng láº¡i trÃ¬nh phiÃªn dá»‹ch ("Killian" sáº½ bá»‹ lÃ£ng quÃªn)

interpreter.messages = messages # Tiáº¿p tá»¥c cuá»™c trÃ² chuyá»‡n tá»« 'messages' ("Killian" sáº½ Ä‘Æ°á»£c ghi nhá»›)
```

### CÃ¡ nhÃ¢n hoÃ¡ tin nháº¯n tá»« há»‡ thá»‘ng

Báº¡n cÃ³ thá»ƒ kiáº¿m tra vÃ  Ä‘iá»u chá»‰nh tin nháº¯n há»‡ thá»‘ng tá»« Optá»« Interpreter Ä‘á»ƒ má»Ÿ rá»™ng chá»©c nÄƒng cá»§a nÃ³, thay Ä‘á»•i quyá»n, hoáº·c Ä‘Æ°a cho nÃ³ nhiá»u ngá»¯ cáº£nh hÆ¡n.

```python
interpreter.system_message += """
Cháº¡y shell commands vá»›i -y Ä‘á»ƒ ngÆ°á»i dÃ¹ng khÃ´ng pháº£i xÃ¡c nháº­n chÃºng.
"""
print(interpreter.system_message)
```

### Thay Ä‘á»•i mÃ´ hÃ¬nh ngÃ´n ngá»¯

Open Interpreter sá»­ dá»¥ng mÃ´ hÃ¬nh [LiteLLM](https://docs.litellm.ai/docs/providers/) Ä‘á»ƒ káº¿t ná»‘i tá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c lÆ°u trá»¯ trÆ°á»›c Ä‘Ã³.

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i mÃ´ hÃ¬nh ngÃ´n ngá»¯ báº±ng cÃ¡ch thay Ä‘á»•i tham sá»‘ mÃ´ hÃ¬nh:
```shell
interpreter --model gpt-3.5-turbo
interpreter --model claude-2
interpreter --model command-nightly
```

á» trong Python, Ä‘á»•i model báº±ng cÃ¡ch thay Ä‘á»•i Ä‘á»‘i tÆ°á»£ng:

```python
interpreter.model = "gpt-3.5-turbo"
```

[TÃ¬m tÃªn chuá»—i "mÃ´ hÃ¬nh" phÃ¹ há»£p cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a báº¡n á»Ÿ Ä‘Ã¢y.](https://docs.litellm.ai/docs/providers/)

### Cháº¡y Open Interpreter trÃªn mÃ¡y cá»¥c bá»™

Open Interpreter sá»­ dá»¥ng [LM Studio](https://lmstudio.ai/) Ä‘á»ƒ káº¿t ná»‘i tá»›i cÃ¡c mÃ´ hÃ¬nh cá»¥c bá»™ (thá»­ nghiá»‡m).

CÆ¡ báº£n cháº¡y `interpreter` trong cháº¿ Ä‘á»™ cá»¥c bá»™ tá»« command line:

```shell
interpreter --local
```

**Báº¡n sáº½ cáº§n cháº¡y LM Studio trong ná»n.**

1. Táº£i [https://lmstudio.ai/](https://lmstudio.ai/) vÃ  khá»Ÿi Ä‘á»™ng.
2. Chá»n má»™t mÃ´ hÃ¬nh rá»“i nháº¥n **â†“ Download**.
3. Nháº¥n vÃ o nÃºt **â†”ï¸** á»Ÿ bÃªn trÃ¡i (dÆ°á»›i ğŸ’¬).
4. Chá»n mÃ´ hÃ¬nh cá»§a báº¡n á»Ÿ phÃ­a trÃªn, rá»“i nháº¥n cháº¡y **Start Server**.

Má»™t khi server cháº¡y, báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i Open Interpreter.

(Khi báº¡n cháº¡y lá»‡nh `interpreter --local`, cÃ¡c bÆ°á»›c á»Ÿ dÆ°á»›i sáº½ Ä‘Æ°á»£c hiá»‡n ra.)

> **LÆ°u Ã½:** Cháº¿ Ä‘á»™ cá»¥c bá»™ chá»‰nh `context_window` cá»§a báº¡n tá»›i 3000, vÃ  `max_tokens` cá»§a báº¡n tá»›i 600. Náº¿u mÃ´ hÃ¬nh cá»§a báº¡n cÃ³ cÃ¡c yÃªu cáº§u khÃ¡c, thÃ¬ hÃ£y chá»‰nh cÃ¡c tham sá»‘ thá»§ cÃ´ng (xem bÃªn dÆ°á»›i).

#### Cá»­a sá»• ngá»¯ cáº£nh (Context Window), (Max Tokens)

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i `max_tokens` vÃ  `context_window` (á»Ÿ trong cÃ¡c) of locally running models.

á» cháº¿ Ä‘á»™ cá»¥c bá»™, cÃ¡c cá»­a sá»• ngá»¯ cáº£nh sáº½ tiÃªu Ã­t RAM hÆ¡n, váº­y nÃªn chÃºng tÃ´i khuyáº¿n khÃ­ch dÃ¹ng cá»­a sá»• nhá» hÆ¡n (~1000) náº¿u nhÆ° nÃ³ cháº¡y khÃ´ng á»•n Ä‘á»‹nh / hoáº·c náº¿u nÃ³ cháº­m. Äáº£m báº£o ráº±ng `max_tokens` Ã­t hÆ¡n `context_window`.

```shell
interpreter --local --max_tokens 1000 --context_window 3000
```

### Cháº¿ Ä‘á»™ sá»­a lá»—i

Äá»ƒ giÃºp Ä‘Ã³ng gÃ³p kiá»ƒm tra Open Interpreter, thÃ¬ cháº¿ Ä‘á»™ `--debug` hÆ¡i dÃ i dÃ²ng.

Báº¡n cÃ³ thá»ƒ khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ sá»­a lá»—i báº±ng cÃ¡ch sá»­ dá»¥ng cá» (`interpreter --debug`), hoáº·c mid-chat:

```shell
$ interpreter
...
> %debug true <- Khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ gá»¡ lá»—i

> %debug false <- Táº¯t cháº¿ Ä‘á»™ gá»¡ lá»—i
```

### Lá»‡nh cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c

Trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng nhá»¯ng dÃ²ng lá»‡nh sau Ä‘á»ƒ cáº£i thiá»‡n tráº£i nghiá»‡m cá»§a mÃ¬nh. ÄÃ¢y lÃ  danh sÃ¡ch cÃ¡c dÃ²ng lá»‡nh cÃ³ sáºµn:

**CÃ¡c lá»‡nh cÃ³ sáºµn:**

- `%debug [true/false]`: Báº­t cháº¿ Ä‘á»™ gá»¡ lá»—i. CÃ³ hay khÃ´ng cÃ³ `true` Ä‘á»u khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ gá»¡ lá»—i. Vá»›i `false` thÃ¬ nÃ³ táº¯t cháº¿ Ä‘á»™ gá»¡ lá»—i.
- `%reset`: Khá»Ÿi Ä‘á»™ng láº¡i toÃ n bá»™ phiÃªn trÃ² chuyá»‡n hiá»‡n táº¡i.
- `%undo`: XÃ³a tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c Ä‘Ã³ vÃ  pháº£n há»“i cá»§a AI khá»i lá»‹ch sá»­ tin nháº¯n.
- `%save_message [path]`: LÆ°u tin nháº¯n vÃ o má»™t Ä‘Æ°á»ng dáº«n JSON Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh tá»« trÆ°á»›c. Náº¿u khÃ´ng cÃ³ Ä‘Æ°á»ng dáº«n nÃ o Ä‘Æ°á»£c cung cáº¥p, nÃ³ sáº½ máº·c Ä‘á»‹nh lÃ  `messages.json`.
- `%load_message [path]`: Táº£i tin nháº¯n tá»« má»™t Ä‘Æ°á»ng dáº«n JSON Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh. Náº¿u khÃ´ng cÃ³ Ä‘Æ°á»ng dáº«n nÃ o Ä‘Æ°á»£c cung cáº¥p, nÃ³ sáº½ máº·c Ä‘á»‹nh lÃ  `messages.json`.
- `%tokens [prompt]`: (_Experimental_) TÃ­nh toÃ¡n cÃ¡c token sáº½ Ä‘Æ°á»£c gá»­i cÃ¹ng vá»›i lá»i nháº¯c tiáº¿p theo dÆ°á»›i dáº¡ng ngá»¯ cáº£nh vÃ  hao tá»•n. TÃ¹y chá»n tÃ­nh toÃ¡n token vÃ  hao tá»•n Æ°á»›c tÃ­nh cá»§a má»™t `prompt` náº¿u Ä‘Æ°á»£c cung cáº¥p. Dá»±a vÃ o [hÃ m `cost_per_token()` cá»§a mÃ´ hÃ¬nh LiteLLM](https://docs.litellm.ai/docs/completion/token_usage#2-cost_per_token) Ä‘á»ƒ tÃ­nh toÃ¡n hao tá»•n.
- `%help`: Hiá»‡n lÃªn trá»£ giÃºp cho cuá»™c trÃ² chuyá»‡n.

### Cáº¥u hÃ¬nh cÃ i

Open Interpreter cho phÃ©p báº¡n thiáº¿t láº­p cÃ¡c tÃ¡c vá»¥ máº·c Ä‘á»‹nh báº±ng cÃ¡ch sá»­ dá»¥ng file `config.yaml`.

Äiá»u nÃ y cung cáº¥p má»™t cÃ¡ch linh hoáº¡t Ä‘á»ƒ Ä‘á»‹nh cáº¥u hÃ¬nh trÃ¬nh thÃ´ng dá»‹ch mÃ  khÃ´ng cáº§n thay Ä‘á»•i Ä‘á»‘i sá»‘ dÃ²ng lá»‡nh má»—i láº§n


Cháº¡y lá»‡nh sau Ä‘á»ƒ má»Ÿ tá»‡p cáº¥u hÃ¬nh:

```
interpreter --config
```

#### Cáº¥u hÃ¬nh cho nhiá»u tá»‡p

Open Interpreter há»— trá»£ nhiá»u file `config.yaml`, cho phÃ©p báº¡n dá»… dÃ ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c cáº¥u hÃ¬nh thÃ´ng qua lá»‡nh `--config_file`.

**ChÃº Ã½**: `--config_file` cháº¥p nháº­n tÃªn tá»‡p hoáº·c Ä‘Æ°á»ng dáº«n tá»‡p. TÃªn tá»‡p sáº½ sá»­ dá»¥ng thÆ° má»¥c cáº¥u hÃ¬nh máº·c Ä‘á»‹nh, trong khi Ä‘Æ°á»ng dáº«n tá»‡p sáº½ sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n Ä‘Ã£ chá»‰ Ä‘á»‹nh.

Äá»ƒ táº¡o hoáº·c chá»‰nh sá»­a cáº¥u hÃ¬nh má»›i, hÃ£y cháº¡y:

```
interpreter --config --config_file $config_path
```

Äá»ƒ yÃªu cáº§u Open Interpreter cháº¡y má»™t tá»‡p cáº¥u hÃ¬nh cá»¥ thá»ƒ, hÃ£y cháº¡y:

```
interpreter --config_file $config_path
```

**ChÃº Ã½**: Thay Ä‘á»•i `$config_path` vá»›i tÃªn hoáº·c Ä‘Æ°á»ng dáº«n Ä‘áº¿n tá»‡p cáº¥u hÃ¬nh cá»§a báº¡n.

##### VÃ­ dá»¥ CLI 

1. Táº¡o má»›i má»™t file `config.turbo.yaml`
   ```
   interpreter --config --config_file config.turbo.yaml
   ```
2. Cháº¡y file `config.turbo.yaml`Ä‘á»ƒ Ä‘áº·t láº¡i `model` thÃ nh `gpt-3.5-turbo`
3. Cháº¡y Open Interpreter vá»›i cáº¥u hÃ¬nh `config.turbo.yaml
   ```
   interpreter --config_file config.turbo.yaml
   ```

##### VÃ­ dá»¥ Python

Báº¡n cÅ©ng cÃ³ thá»ƒ táº£i cÃ¡c tá»‡p cáº¥u hÃ¬nh khi gá»i Open Interpreter tá»« táº­p lá»‡nh Python:

```python
import os
import interpreter

currentPath = os.path.dirname(os.path.abspath(__file__))
config_path=os.path.join(currentPath, './config.test.yaml')

interpreter.extend_config(config_path=config_path)

message = "What operating system are we on?"

for chunk in interpreter.chat(message, display=False, stream=True):
  print(chunk)
```

## MÃ¡y chá»§ FastAPI máº«u

Báº£n cáº­p nháº­t trÃ¬nh táº¡o cho phÃ©p Ä‘iá»u khiá»ƒn TrÃ¬nh thÃ´ng dá»‹ch má»Ÿ thÃ´ng qua cÃ¡c Ä‘iá»ƒm cuá»‘i HTTP REST:

```python
# server.py

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import interpreter

app = FastAPI()

@app.get("/chat")
def chat_endpoint(message: str):
    def event_stream():
        for result in interpreter.chat(message, stream=True):
            yield f"data: {result}\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")

@app.get("/history")
def history_endpoint():
    return interpreter.messages
```

```shell
pip install fastapi uvicorn
uvicorn server:app --reload
```

## HÆ°á»›ng dáº«n an toÃ n

VÃ¬ mÃ£ Ä‘Æ°á»£c táº¡o Ä‘Æ°á»£c thá»±c thi trong mÃ´i trÆ°á»ng cá»¥c bá»™ cá»§a báº¡n nÃªn nÃ³ cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c tá»‡p vÃ  cÃ i Ä‘áº·t há»‡ thá»‘ng cá»§a báº¡n, cÃ³ kháº£ nÄƒng dáº«n Ä‘áº¿n cÃ¡c káº¿t quáº£ khÃ´ng mong muá»‘n nhÆ° máº¥t dá»¯ liá»‡u hoáº·c rá»§i ro báº£o máº­t.

**âš ï¸ Open Interpreter sáº½ yÃªu cáº§u xÃ¡c nháº­n cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c khi cháº¡y code.**

Báº¡n cÃ³ thá»ƒ cháº¡y `interpreter -y` hoáº·c Ä‘áº·t `interpreter.auto_run = True` Ä‘á»ƒ bá» qua xÃ¡c nháº­n nÃ y, trong trÆ°á»ng há»£p Ä‘Ã³:

- HÃ£y tháº­n trá»ng khi yÃªu cáº§u cÃ¡c lá»‡nh sá»­a Ä‘á»•i tá»‡p hoáº·c cÃ i Ä‘áº·t há»‡ thá»‘ng.
- Theo dÃµi Open Interpreter giá»‘ng nhÆ° má»™t chiáº¿c Ã´ tÃ´ tá»± lÃ¡i vÃ  sáºµn sÃ ng káº¿t thÃºc quÃ¡ trÃ¬nh báº±ng cÃ¡ch Ä‘Ã³ng terminal cá»§a báº¡n.
- CÃ¢n nháº¯c viá»‡c cháº¡y Open Interpreter trong mÃ´i trÆ°á»ng bá»‹ háº¡n cháº¿ nhÆ° Google Colab hoáº·c Replit. Nhá»¯ng mÃ´i trÆ°á»ng nÃ y biá»‡t láº­p hÆ¡n, giáº£m thiá»ƒu rá»§i ro khi cháº¡y code tÃ¹y Ã½.

ÄÃ¢y lÃ  há»— trá»£ **thá»­ nghiá»‡m** cho [cháº¿ Ä‘á»™ an toÃ n](docs/SAFE_MODE.md) giÃºp giáº£m thiá»ƒu rá»§i ro.

## NÃ³ hoáº¡t Ä‘á»™ng tháº¿ nÃ o?

Open Interpreter trang bá»‹ [mÃ´ hÃ¬nh ngÃ´n ngá»¯ gá»i hÃ m](https://platform.openai.com/docs/guides/gpt/function-calling) vá»›i má»™t hÃ m `exec()`, cháº¥p nháº­n má»™t `language` (nhÆ° "Python" hoáº·c "JavaScript") vÃ  `code` Ä‘á»ƒ cháº¡y.

Sau Ä‘Ã³, chÃºng tÃ´i truyá»n trá»±c tuyáº¿n thÃ´ng bÃ¡o, mÃ£ cá»§a mÃ´ hÃ¬nh vÃ  káº¿t quáº£ Ä‘áº§u ra cá»§a há»‡ thá»‘ng cá»§a báº¡n Ä‘áº¿n terminal dÆ°á»›i dáº¡ng Markdown.

# ÄÃ³ng gÃ³p

Cáº£m Æ¡n báº¡n Ä‘Ã£ quan tÃ¢m Ä‘Ã³ng gÃ³p! ChÃºng tÃ´i hoan nghÃªnh sá»± tham gia cá»§a cá»™ng Ä‘á»“ng.

Vui lÃ²ng xem [HÆ°á»›ng dáº«n Ä‘Ã³ng gÃ³p](CONTRIBUTING.md) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t cÃ¡ch tham gia.

## Giáº¥y phÃ©p

Open Interpreter Ä‘Æ°á»£c cáº¥p phÃ©p theo Giáº¥y phÃ©p MIT. Báº¡n Ä‘Æ°á»£c phÃ©p sá»­ dá»¥ng, sao chÃ©p, sá»­a Ä‘á»•i, phÃ¢n phá»‘i, cáº¥p phÃ©p láº¡i vÃ  bÃ¡n cÃ¡c báº£n sao cá»§a pháº§n má»m.

**LÆ°u Ã½**: Pháº§n má»m nÃ y khÃ´ng liÃªn káº¿t vá»›i OpenAI.

> CÃ³ quyá»n truy cáº­p vÃ o má»™t láº­p trÃ¬nh viÃªn cáº¥p dÆ°á»›i lÃ m viá»‡c nhanh chÃ³ng trong táº§m tay báº¡n ... cÃ³ thá»ƒ khiáº¿n quy trÃ¬nh lÃ m viá»‡c má»›i trá»Ÿ nÃªn dá»… dÃ ng vÃ  hiá»‡u quáº£, cÅ©ng nhÆ° má»Ÿ ra nhá»¯ng lá»£i Ã­ch cá»§a viá»‡c láº­p trÃ¬nh cho ngÆ°á»i má»›i.
>
> â€” _PhÃ¡t hÃ nh trÃ¬nh thÃ´ng dá»‹ch mÃ£ cá»§a OpenAI_

<br>
