<h1 align="center">â— Open Interpreter</h1>

<p align="center">
    <a href="https://discord.gg/6p3fD6rBVm">
        <img alt="Discord" src="https://img.shields.io/discord/1146610656779440188?logo=discord&style=flat&logoColor=white"/></a>
    <a href="README_ES.md"> <img src="https://img.shields.io/badge/EspaÃ±ol-white.svg" alt="ES doc"/></a>
    <a href="docs/README_JA.md"><img src="https://img.shields.io/badge/ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ-æ—¥æœ¬èª-white.svg" alt="JA doc"/></a>
    <a href="docs/README_ZH.md"><img src="https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-white.svg" alt="ZH doc"/></a>
    <a href="README_UK.md"><img src="https://img.shields.io/badge/Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°-white.svg" alt="UK doc"/></a>
    <a href="docs/README_IN.md"><img src="https://img.shields.io/badge/Hindi-white.svg" alt="IN doc"/></a>
    <a href="../LICENSE"><img src="https://img.shields.io/static/v1?label=license&message=AGPL&color=white&style=flat" alt="License"/></a>
    <br>
    <br><a href="https://openinterpreter.com">Quyá»n truy cáº­p sá»›m dÃ nh cho á»©ng dung trÃªn mÃ¡y tÃ­nh</a>â€ â€ |â€ â€ <b><a href="https://docs.openinterpreter.com/">TÃ i liá»‡u tham kháº£o</a></b><br>
</p>

<br>

<img alt="local_explorer" src="https://github.com/OpenInterpreter/open-interpreter/assets/63927363/d941c3b4-b5ad-4642-992c-40edf31e2e7a">

<br>

```shell
pip install open-interpreter
```

> KhÃ´ng cÃ i Ä‘áº·t Ä‘Æ°á»£c? HÃ£y Ä‘á»c [hÆ°á»›ng dáº«n setup](https://docs.openinterpreter.com/getting-started/setup).

```shell
interpreter
```

<br>

**Open Interpreter** sáº½ giÃºp LLMs cháº¡y code (Python, Javascript, Shell,...) trÃªn mÃ¡y tÃ­nh local cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ nÃ³i chuyá»‡n vá»›i Open Interpreter thÃ´ng qua giao diá»‡n giá»‘ng vá»›i ChatGPT ngay trÃªn terminal cá»§a báº¡n báº±ng cÃ¡ch cháº¡y lá»‡nh `$ interpreter` sau khi cÃ i Ä‘áº·t thÃ nh cÃ´ng.

CÃ¡c tÃ­nh nÄƒng chung giao diá»‡n ngÃ´n ngá»¯ tá»± nhiÃªn mang láº¡i

- Táº¡o vÃ  chá»‰nh sá»­a áº£nh, videos, PDF,...
- Äiá»u khiá»ƒn trÃ¬nh duyá»‡t Chrome Ä‘á»ƒ tiáº¿n hÃ nh nghiÃªn cá»©u
- Váº½, lÃ m sáº¡ch vÃ  phÃ¢n tÃ­ch cÃ¡c táº­p dá»¯ liá»‡u lá»›n (large datasets)
- ...vÃ  nhiá»u hÆ¡n tháº¿ ná»¯a.

**âš ï¸ LÆ°u Ã½: Báº¡n sáº½ Ä‘Æ°á»£c yÃªu cáº§u phÃª duyá»‡t code trÆ°á»›c khi cháº¡y.**

<br>

## Demo

https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60

#### Báº£n demo cÃ³ sáºµn trÃªn Google Colab:

[![Má»Ÿ trong Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing)

#### Äi kÃ¨m vá»›i á»©ng dá»¥ng demo qua tÆ°Æ¡ng tÃ¡c giá»ng nÃ³i, láº¥y cáº£m há»©ng tá»« _CÃ´ áº¥y_:

[![Má»Ÿ trong Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1NojYGHDgxH6Y1G1oxThEBBb2AtyODBIK)

## HÆ°á»›ng dáº«n khá»Ÿi dá»™ng nhanh

```shell
pip install open-interpreter
```

### Terminal

Sau khi cÃ i Ä‘áº·t, cháº¡y lá»‡nh `interpreter`:

```shell
interpreter
```

### Python

```python
from interpreter import interpreter

interpreter.chat("Plot AAPL and META's normalized stock prices") # Cháº¡y trÃªn 1 dÃ²ng lá»‡nh
interpreter.chat() # Khá»Ÿi Ä‘á»™ng chat cÃ³ kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c
```

### GitHub Codespaces

Nháº¥n phÃ­m `,` trÃªn trang GitHub cá»§a repo nÃ y Ä‘á»ƒ táº¡o codespace. Sau má»™t lÃ¡t, báº¡n sáº½ nháº­n Ä‘Æ°á»£c mÃ´i trÆ°á»ng mÃ¡y áº£o cloud Ä‘Æ°á»£c cÃ i Ä‘áº·t sáºµn vá»›i open-interpreter. Sau Ä‘Ã³, báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u tÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p vá»›i nÃ³ vÃ  thoáº£i mÃ¡i thá»±c thi cÃ¡c lá»‡nh mÃ  khÃ´ng lo hÆ° há»ng há»‡ thá»‘ng.

## So sÃ¡nh Code Interpreter cá»§a ChatGPT

Báº£n phÃ¡t hÃ nh cá»§a OpenAI [Code Interpreter](https://openai.com/blog/chatgpt-plugins#code-interpreter) sá»­ dá»¥ng GPT-4 tÄƒng kháº£ nÄƒng hoÃ n thiá»‡n váº¥n Ä‘á» thá»±c tiá»…n vá»›i ChatGPT.

Tuy nhiÃªn, dá»‹ch vá»¥ cá»§a OpenAI Ä‘Æ°á»£c lÆ°u trá»¯, mÃ£ nguá»“n Ä‘Ã³ng, vÃ  ráº¥t háº¡n cháº¿:

- KhÃ´ng cÃ³ truy cáº­p Internet.
- [Sá»‘ lÆ°á»£ng gÃ³i cÃ i Ä‘áº·t há»— trá»¡ cÃ³ sáºµn giá»›i háº¡n](https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/).
- Tá»‘c Ä‘á»™ upload tá»‘i Ä‘a 100 MB, timeout giá»›i háº¡n 120.0 giÃ¢y .
- Tin nháº¯n kÃ¨m vá»›i cÃ¡c file vÃ  liÃªn káº¿t Ä‘Æ°á»£c táº¡o trÆ°á»›c Ä‘Ã³ sáº½ bá»‹ xÃ³a khi Ä‘Ã³ng mÃ´i trÆ°á»ng láº¡i.

---

Open Interpreter kháº¯c phá»¥c nhá»¯ng háº¡n cháº¿ nÃ y báº±ng cÃ¡ch cháº¡y local trong mÃ´i trÆ°á»ng mÃ¡y tÃ­nh cá»§a báº¡n. NÃ³ cÃ³ toÃ n quyá»n truy cáº­p vÃ o Internet, khÃ´ng bá»‹ háº¡n cháº¿ vá» thá»i gian hoáº·c kÃ­ch thÆ°á»›c file vÃ  cÃ³ thá»ƒ sá»­ dá»¥ng báº¥t ká»³ gÃ³i hoáº·c thÆ° viá»‡n nÃ o.

ÄÃ¢y lÃ  sá»± káº¿t há»£p sá»©c máº¡nh cá»§a mÃ£ nguá»“n cá»§a GPT-4 vá»›i tÃ­nh linh hoáº¡t cá»§a mÃ´i trÆ°á»ng phÃ¡t triá»ƒn local cá»§a báº¡n.

## CÃ¡c lá»‡nh

**Update:** Cáº­p nháº­t trÃ¬nh táº¡o lá»‡nh (0.1.5) giá»›i thiá»‡u tÃ­nh nÄƒng streaming:

```python
message = "What operating system are we on?"

for chunk in interpreter.chat(message, display=False, stream=True):
  print(chunk)
```

### TrÃ² chuyá»‡n tÆ°Æ¡ng tÃ¡c

Äá»ƒ táº¡o má»™t cuá»™c trÃ² chuyá»‡n tÆ°Æ¡ng tÃ¡c tá»« terminal cá»§a báº¡n, cháº¡y `interpreter` báº±ng dÃ²ng lá»‡nh:

```shell
interpreter
```

hoáº·c `interpreter.chat()` tá»« file .py :

```python
interpreter.chat()
```

**Báº¡n cÅ©ng cÃ³ thá»ƒ streaming tá»«ng chunk:**

```python
message = "What operating system are we on?"

for chunk in interpreter.chat(message, display=False, stream=True):
  print(chunk)
```

### Láº­p trÃ¬nh cuá»™c trÃ² chuyá»‡n

Äá»ƒ kiá»ƒm soÃ¡t tá»‘t hÆ¡n, báº¡n cÃ³ thá»ƒ gá»­i tin nháº¯n trá»±c tiáº¿p qua `.chat(message)`:

```python
interpreter.chat("Add subtitles to all videos in /videos.")

# ... Stream dá»¯ liá»‡u output Ä‘áº¿n terminal cá»§a báº¡n vÃ  hoÃ n thÃ nh tÃ¡c vá»¥ ...

interpreter.chat("These look great but can you make the subtitles bigger?")

# ...
```

### Táº¡o má»™t cuá»™c trÃ² chuyá»‡n má»›i:

Trong Python, Open Interpreter ghi nhá»› lá»‹ch sá»­ há»™i thoáº¡i, náº¿u muá»‘n báº¯t Ä‘áº§u láº¡i tá»« Ä‘áº§u, báº¡n cÃ³ thá»ƒ reset:

```python
interpreter.messages = []
```

### LÆ°u vÃ  khÃ´i phá»¥c cuá»™c trÃ² chuyá»‡n

`interpreter.chat()` tráº£ vá» danh sÃ¡ch tin nháº¯n, cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tiáº¿p tá»¥c cuá»™c trÃ² chuyá»‡n vá»›i `interpreter.messages = messages`:

```python
messages = interpreter.chat("My name is Hung.") # LÆ°u tin nháº¯n tá»›i 'messages'
interpreter.messages = [] # Khá»Ÿi Ä‘á»™ng láº¡i trÃ¬nh phiÃªn dá»‹ch ("Hung" sáº½ bá»‹ lÃ£ng quÃªn)

interpreter.messages = messages # Tiáº¿p tá»¥c cuá»™c trÃ² chuyá»‡n tá»« 'messages' ("Hung" sáº½ Ä‘Æ°á»£c ghi nhá»›)
```

### CÃ¡ nhÃ¢n hoÃ¡ tin nháº¯n tá»« há»‡ thá»‘ng

Báº¡n cÃ³ thá»ƒ kiáº¿m tra vÃ  Ä‘iá»u chá»‰nh tin nháº¯n há»‡ thá»‘ng tá»« Open Interpreter Ä‘á»ƒ má»Ÿ rá»™ng chá»©c nÄƒng, thay Ä‘á»•i quyá»n, hoáº·c táº¡o ra nhiá»u ngá»¯ cáº£nh hÆ¡n.

```python
interpreter.system_message += """
Run shell commands with -y so the user doesn't have to confirm them.
"""
print(interpreter.system_message)
```

### Thay Ä‘á»•i mÃ´ hÃ¬nh ngÃ´n ngá»¯ (Language Model)

Open Interpreter sá»­ dá»¥ng mÃ´ hÃ¬nh [LiteLLM](https://docs.litellm.ai/docs/providers/) Ä‘á»ƒ káº¿t ná»‘i tá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘ang Ä‘Æ°á»£c host.

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i mÃ´ hÃ¬nh ngÃ´n ngá»¯ báº±ng cÃ¡ch thay Ä‘á»•i tham sá»‘ model:

```shell
interpreter --model gpt-3.5-turbo
interpreter --model claude-2
interpreter --model command-nightly
```

á» trong Python, Ä‘á»•i model báº±ng cÃ¡ch thay Ä‘á»•i Ä‘á»‘i tÆ°á»£ng:

```python
interpreter.llm.model = "gpt-3.5-turbo"
```

[TÃ¬m tÃªn chuá»—i "model" phÃ¹ há»£p cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a báº¡n á»Ÿ Ä‘Ã¢y.](https://docs.litellm.ai/docs/providers/)

### Cháº¡y Open Interpreter trÃªn local

#### Terminal

Open Interpreter cÃ³ thá»ƒ sá»­ dá»¥ng mÃ¡y chá»§ tÆ°Æ¡ng thÃ­ch vá»›i OpenAI Ä‘á»ƒ cháº¡y cÃ¡c mÃ´ hÃ¬nh local. (LM Studio, jan.ai, ollama, v.v.)

Chá»‰ cáº§n cháº¡y `interpreter` vá»›i URL api_base cá»§a mÃ¡y chá»§ suy luáº­n cá»§a báº¡n (Ä‘á»‘i vá»›i LM studio máº·c Ä‘á»‹nh lÃ  `http://localhost:1234/v1`):

```shell
interpreter --api_base "http://localhost:1234/v1" --api_key "fake_key"
```

NgoÃ i ra, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Llamafile mÃ  khÃ´ng cáº§n cÃ i Ä‘áº·t báº¥t ká»³ pháº§n má»m bÃªn thá»© ba nÃ o báº±ng cÃ¡ch cháº¡y:

```shell
interpreter --local
```

Äá»ƒ Ä‘Æ°á»£c hÆ°á»›ng dáº«n chi tiáº¿t hÆ¡n, hÃ£y xem [video nÃ y cá»§a Mike Bird](https://www.youtube.com/watch?v=CEs51hGWuGU?si=cN7f6QhfT4edfG5H)

**Äá»ƒ cháº¡y LM Studio á»Ÿ cháº¿ Ä‘á»™ background.**

1. Táº£i [https://lmstudio.ai/](https://lmstudio.ai/) vÃ  khá»Ÿi Ä‘á»™ng.
2. Chá»n má»™t mÃ´ hÃ¬nh rá»“i nháº¥n **â†“ Download**.
3. Nháº¥n vÃ o nÃºt **â†”ï¸** á»Ÿ bÃªn trÃ¡i (dÆ°á»›i ğŸ’¬).
4. Chá»n mÃ´ hÃ¬nh cá»§a báº¡n á»Ÿ phÃ­a trÃªn, rá»“i nháº¥n cháº¡y **Start Server**.

Má»™t khi server cháº¡y, báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i Open Interpreter.

> **LÆ°u Ã½:** Cháº¿ Ä‘á»™ local chá»‰nh `context_window` cá»§a báº¡n tá»›i 3000, vÃ  `max_tokens` cá»§a báº¡n tá»›i 600. Náº¿u mÃ´ hÃ¬nh cá»§a báº¡n cÃ³ cÃ¡c yÃªu cáº§u khÃ¡c, thÃ¬ hÃ£y chá»‰nh cÃ¡c tham sá»‘ thá»§ cÃ´ng (xem bÃªn dÆ°á»›i).

#### Python

Our Python package gives you more control over each setting. To replicate and connect to LM Studio, use these settings:

```python
from interpreter import interpreter

interpreter.offline = True # Táº¯t cÃ¡c tÃ­nh nÄƒng online nhÆ° Open Procedures
interpreter.llm.model = "openai/x" # CÃ i Ä‘áº·t OI gá»­i tin nháº¯n trong format cá»§a OpenAI
interpreter.llm.api_key = "fake_key" # LiteLLM dÃ¹ng Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i LM Studio, báº¯t buá»™c pháº£i cÃ³
interpreter.llm.api_base = "http://localhost:1234/v1" # Endpoint cá»§a sever OpenAI báº¥t ká»³ nÃ o Ä‘Ã³

interpreter.chat()
```

#### Cá»­a sá»• ngá»¯ cáº£nh (Context Window), lÆ°á»£ng token tá»‘i Ä‘a (Max Tokens)

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i `max_tokens` vÃ  `context_window` trong cÃ¡c model cháº¡y trÃªn local.

á» cháº¿ Ä‘á»™ local, cÃ¡c cá»­a sá»• ngá»¯ cáº£nh sáº½ tiÃªu Ã­t RAM hÆ¡n, váº­y nÃªn chÃºng tÃ´i khuyáº¿n khÃ­ch dÃ¹ng cá»­a sá»• nhá» hÆ¡n (~1000) náº¿u nhÆ° nÃ³ cháº¡y khÃ´ng á»•n Ä‘á»‹nh / hoáº·c náº¿u nÃ³ cháº­m. HÃ£y Ä‘áº£m báº£o ráº±ng `max_tokens` Ã­t hÆ¡n `context_window`.

```shell
interpreter --local --max_tokens 1000 --context_window 3000
```

### Cháº¿ Ä‘á»™ verbose

Äá»ƒ giÃºp Ä‘Ã³ng gÃ³p kiá»ƒm tra Open Interpreter, thÃ¬ cháº¿ Ä‘á»™ `--verbose` hÆ¡i dÃ i dÃ²ng.

Báº¡n cÃ³ thá»ƒ khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ verbose báº±ng cÃ¡ch sá»­ dá»¥ng cá» (`interpreter --verbose`), hoáº·c mid-chat:

```shell
$ interpreter
...
> %verbose true <- Khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ verbose

> %verbose false <- Táº¯t cháº¿ Ä‘á»™ verbose
```

### CÃ¡c lá»‡nh trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c

Trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng nhá»¯ng dÃ²ng lá»‡nh sau Ä‘á»ƒ cáº£i thiá»‡n tráº£i nghiá»‡m cá»§a mÃ¬nh. ÄÃ¢y lÃ  danh sÃ¡ch cÃ¡c dÃ²ng lá»‡nh cÃ³ sáºµn:

**CÃ¡c lá»‡nh cÃ³ sáºµn:**

- `%verbose [true/false]`: Báº­t cháº¿ Ä‘á»™ verbose. CÃ³ hoáº·c khÃ´ng cÃ³ `true` sáº½ Ä‘á»u khá»Ÿi Ä‘á»™ng cháº¿ Ä‘á»™ verbose. Vá»›i `false` thÃ¬ nÃ³ táº¯t cháº¿ Ä‘á»™ verbose.
- `%reset`: Khá»Ÿi Ä‘á»™ng láº¡i toÃ n bá»™ phiÃªn trÃ² chuyá»‡n hiá»‡n táº¡i.
- `%undo`: XÃ³a tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c Ä‘Ã³ vÃ  pháº£n há»“i cá»§a AI khá»i lá»‹ch sá»­ tin nháº¯n.
- `%tokens [prompt]`: (_Experimental_) TÃ­nh toÃ¡n cÃ¡c token sáº½ Ä‘Æ°á»£c gá»­i cÃ¹ng vá»›i lá»i nháº¯c tiáº¿p theo dÆ°á»›i dáº¡ng ngá»¯ cáº£nh vÃ  chi phÃ­. TÃ¹y chá»n tÃ­nh toÃ¡n token vÃ  chÃ­ phÃ­ Æ°á»›c tÃ­nh cá»§a má»™t `prompt` náº¿u Ä‘Æ°á»£c cung cáº¥p. Dá»±a vÃ o [hÃ m `cost_per_token()` cá»§a mÃ´ hÃ¬nh LiteLLM](https://docs.litellm.ai/docs/completion/token_usage#2-cost_per_token) Ä‘á»ƒ tÃ­nh toÃ¡n.
- `%help`: Hiá»‡n lÃªn trá»£ giÃºp cho cuá»™c trÃ² chuyá»‡n.

### Cáº¥u hÃ¬nh / Profiles

Open Interpreter cho phÃ©p báº¡n thiáº¿t láº­p cÃ¡c hÃ nh vi máº·c Ä‘á»‹nh báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c file `yaml`.

ÄÃ¢y lÃ  cÃ¡ch linh hoáº¡t Ä‘á»ƒ cáº¥u hÃ¬nh trÃ¬nh thÃ´ng dá»‹ch mÃ  khÃ´ng cáº§n thay Ä‘á»•i dÃ²ng lá»‡nh má»—i láº§n.

Cháº¡y lá»‡nh sau Ä‘á»ƒ má»Ÿ thÆ° má»¥c profile:

```
interpreter --profiles
```

Báº¡n cÃ³ thá»ƒ thÃªm táº­p tin `yaml` vÃ o Ä‘Ã³. Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh cÃ³ tÃªn lÃ  `default.yaml`.

#### Multiple Profiles

Open Interpreter há»— trá»£ nhiá»u file `yaml`, cho phÃ©p báº¡n dá»… dÃ ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c cáº¥u hÃ¬nh:

```
interpreter --profile my_profile.yaml
```

## MÃ¡y chá»§ FastAPI máº«u

Báº£n cáº­p nháº­t generator cho phÃ©p Ä‘iá»u khiá»ƒn Open Interpreter thÃ´ng qua cÃ¡c endpoint HTTP REST:

```python
# server.py

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from interpreter import interpreter

app = FastAPI()

@app.get("/chat")
def chat_endpoint(message: str):
    def event_stream():
        for result in interpreter.chat(message, stream=True):
            yield f"data: {result}\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")

@app.get("/history")
def history_endpoint():
    return interpreter.messages
```

```shell
pip install fastapi uvicorn
uvicorn server:app --reload
```

Báº¡n cÅ©ng cÃ³ thá»ƒ khá»Ÿi Ä‘á»™ng má»™t mÃ¡y chá»§ giá»‘ng há»‡t mÃ¡y chá»§ á»Ÿ trÃªn báº±ng cÃ¡ch cháº¡y `interpreter.server()`.

## Android

Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c Ä‘á»ƒ cÃ i Ä‘áº·t Open Interpreter trÃªn thiáº¿t bá»‹ Android cá»§a mÃ¬nh trong [repo open-interpreter-termux](https://github.com/MikeBirdTech/open-interpreter-termux).

## LÆ°u Ã½ an toÃ n

VÃ¬ code táº¡o Ä‘Æ°á»£c thá»±c thi trong mÃ´i trÆ°á»ng local cá»§a báº¡n nÃªn nÃ³ cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c file vÃ  cÃ i Ä‘áº·t há»‡ thá»‘ng cá»§a báº¡n, cÃ³ kháº£ nÄƒng dáº«n Ä‘áº¿n cÃ¡c káº¿t quáº£ khÃ´ng mong muá»‘n nhÆ° máº¥t dá»¯ liá»‡u hoáº·c rá»§i ro báº£o máº­t.

**âš ï¸ Open Interpreter sáº½ yÃªu cáº§u xÃ¡c nháº­n cá»§a ngÆ°á»i dÃ¹ng trÆ°á»›c khi cháº¡y code.**

Báº¡n cÃ³ thá»ƒ cháº¡y `interpreter -y` hoáº·c Ä‘áº·t `interpreter.auto_run = True` Ä‘á»ƒ bá» qua xÃ¡c nháº­n nÃ y, trong trÆ°á»ng há»£p Ä‘Ã³:

- HÃ£y tháº­n trá»ng khi yÃªu cáº§u cÃ¡c lá»‡nh sá»­a Ä‘á»•i file hoáº·c cÃ i Ä‘áº·t há»‡ thá»‘ng.
- Theo dÃµi Open Interpreter giá»‘ng nhÆ° má»™t chiáº¿c Ã´ tÃ´ tá»± lÃ¡i vÃ  sáºµn sÃ ng káº¿t thÃºc process báº±ng cÃ¡ch Ä‘Ã³ng terminal cá»§a báº¡n.
- CÃ¢n nháº¯c viá»‡c cháº¡y Open Interpreter trong mÃ´i trÆ°á»ng bá»‹ háº¡n cháº¿ nhÆ° Google Colab hoáº·c Replit. Nhá»¯ng mÃ´i trÆ°á»ng nÃ y biá»‡t láº­p hÆ¡n, giáº£m thiá»ƒu rá»§i ro khi cháº¡y code.

ÄÃ¢y lÃ  há»— trá»£ **thá»­ nghiá»‡m** cho [cháº¿ Ä‘á»™ an toÃ n](https://github.com/OpenInterpreter/open-interpreter/blob/main/docs/SAFE_MODE.md) giÃºp giáº£m thiá»ƒu rá»§i ro.

## CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng

Open Interpreter sá»­ dá»¥ng [mÃ´ hÃ¬nh ngÃ´n ngá»¯ gá»i hÃ m (function-calling language model)](https://platform.openai.com/docs/guides/gpt/function-calling) vá»›i má»™t hÃ m `exec()`, cháº¥p nháº­n má»™t `language` (nhÆ° "Python" hoáº·c "JavaScript") vÃ  `code` Ä‘á»ƒ cháº¡y.

Sau Ä‘Ã³, chÃºng tÃ´i stream tin nháº¯n, code cá»§a mÃ´ hÃ¬nh vÃ  káº¿t quáº£ output cá»§a há»‡ thá»‘ng cá»§a báº¡n Ä‘áº¿n terminal dÆ°á»›i dáº¡ng Markdown.

# Truy cáº­p tÃ i liá»‡u offline

ToÃ n bá»™ [tÃ i liá»‡u](https://docs.openinterpreter.com/) cÃ³ thá»ƒ Ä‘Æ°á»£c truy cáº­p mÃ  khÃ´ng cáº§n káº¿t ná»‘i internet.

[Node](https://nodejs.org/en) cáº§n pháº£i Ä‘Æ°á»£c cÃ i Ä‘áº·t:

- PhiÃªn báº£n 18.17.0 hoáº·c báº¥t ká»³ phiÃªn báº£n 18.x.x nÃ o má»›i hÆ¡n.
- PhiÃªn báº£n 20.3.0 hoáº·c báº¥t ká»³ phiÃªn báº£n 20.x.x nÃ o sau nÃ y.
- Báº¥t ká»³ phiÃªn báº£n nÃ o báº¯t Ä‘áº§u tá»« 21.0.0 trá»Ÿ Ä‘i, khÃ´ng cÃ³ giá»›i háº¡n phiÃªn báº£n má»›i nháº¥t cÃ³ thá»ƒ dÃ¹ng.

CÃ i Ä‘áº·t [Mintlify](https://mintlify.com/):

```bash
npm i -g mintlify@latest
```

Thay Ä‘á»•i vÃ o thÆ° má»¥c docs vÃ  cháº¡y lá»‡nh:

```bash
# Giáº£ sá»­ báº¡n Ä‘ang á»Ÿ thÆ° má»¥c root cá»§a dá»± Ã¡n
cd ./docs

# Cháº¡y server tÃ i liá»‡u trÃªn local
mintlify dev
```

Má»™t cá»­a sá»• trÃ¬nh duyá»‡t má»›i sáº½ má»Ÿ ra. TÃ i liá»‡u sáº½ cÃ³ táº¡i [http://localhost:3000](http://localhost:3000) cho tá»›i khi nÃ o local server váº«n cháº¡y.

# ÄÃ³ng gÃ³p

Cáº£m Æ¡n báº¡n Ä‘Ã£ quan tÃ¢m Ä‘Ã³ng gÃ³p! ChÃºng tÃ´i hoan nghÃªnh sá»± tham gia cá»§a cá»™ng Ä‘á»“ng.

Vui lÃ²ng xem [HÆ°á»›ng dáº«n Ä‘Ã³ng gÃ³p](https://github.com/OpenInterpreter/open-interpreter/blob/main/docs/CONTRIBUTING.md) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t cÃ¡ch tham gia.

# Káº¿ hoáº¡ch tÆ°Æ¡ng lai (Roadmap)

HÃ£y xem qua [roadmap cá»§a chÃºng tÃ´i](https://github.com/OpenInterpreter/open-interpreter/blob/main/docs/ROADMAP.md) Ä‘á»ƒ biáº¿t thÃªm vá» káº¿ hoáº¡ch Open Interpreter trong tÆ°Æ¡ng lai.

**LÆ°u Ã½**: Pháº§n má»m nÃ y khÃ´ng liÃªn káº¿t vá»›i OpenAI.

![thumbnail-ncu](https://github.com/OpenInterpreter/open-interpreter/assets/63927363/1b19a5db-b486-41fd-a7a1-fe2028031686)

> Having access to a junior programmer working at the speed of your fingertips ... can make new workflows effortless and efficient, as well as open the benefits of programming to new audiences.
>
> â€” _OpenAI's Code Interpreter Release_
> Ã nghÄ©a cÃ¢u trÃªn cÃ³ thá»ƒ hiá»ƒu lÃ : HÃ£y xem AI nhÆ° má»™t láº­p trÃ¬nh viÃªn lÃ m viá»‡c nhanh chÃ³ng vÃ  AI sáº½ giÃºp báº¡n láº­p trÃ¬nh hiá»‡u quáº£ hÆ¡n ráº¥t nhiáº¿u.

<br>
